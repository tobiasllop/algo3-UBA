# Práctica 1

### Ejercicio 3
Se nos dice que la matriz es simetrica por lo que primero la completaremos:

$$
\begin{pmatrix}
 0 & 10 & 10 & 1 \\
 10 & 0 & 5 & 2 \\
 10 & 5 & 0 & 1 \\
 1 & 2 & 1 & 0 \\
\end{pmatrix}
$$

#### a.

     def max_subset_sum(M, n, k, i=0, curr_sum=0, curr_subset=[]):
         # Caso base: si ya tenemos k elementos en curr_subset
         if len(curr_subset) == k:
             return curr_sum
     
         # Si ya no quedan más elementos que agregar
         if i == n:
             return 0
     
         # Caso 1: No agregar el elemento i al subconjunto
         omit = max_subset_sum(M, n, k, i+1, curr_sum, curr_subset)
     
         # Caso 2: Agregar el elemento i al subconjunto
         curr_subset.append(i)
         subset_sum = curr_sum
         for j in curr_subset:
             subset_sum += M[i][j] + M[j][i]
         include = max_subset_sum(M, n, k, i+1, subset_sum, curr_subset)
         curr_subset.pop()
     
         # Devolver el máximo de los dos casos
         return max(omit, include)
 
     # Función principal
     def max_subset_matrix_sum(M, k):
         n = len(M)
         return max_subset_sum(M, n, k)
             
#### b.
La complejidad temporal de este algoritmo es O(n * 2^n), ya que en cada nivel del árbol de recursión hay n posibles elementos para agregar al subconjunto, y hay un total de 2^n subconjuntos posibles.

### Ejercicio 4
Escribi el arbol de BT en el cuaderno.

a. 

    import sys

    def encuentra_solucion_optima(D):
        n = len(D)
        solucion_optima = []
        costo_minimo = sys.maxsize

        def backtrack(permutacion, costo, indice):
            nonlocal costo_minimo, solucion_optima

            # Si se han explorado todas las posiciones, actualizar la solución óptima
            if indice == n:
                costo += D[permutacion[-1]][permutacion[0]]  # Agregar el costo de regresar al inicio
                if costo < costo_minimo:
                    costo_minimo = costo
                    solucion_optima = permutacion[:] # Hacer una copia de la permutación
                return

            # Explorar todas las posibilidades para la posición actual
            for i in range(n):
                if i not in permutacion:
                    permutacion.append(i)
                    backtrack(permutacion, costo + D[permutacion[-2]][permutacion[-1]], indice + 1)
                    permutacion.pop()

        backtrack([], 0, 0)
        return solucion_optima, costo_minimo

#### b. 
Complejidad temporal es O(n!) ya que hay que calcular todas las permutaciones y espacial es O(n)
    
#### c. Un ejemplo de poda por optimalidad:
Supongamos que estás intentando resolver el problema mediante backtracking y ya has encontrado una permutación $\pi$ con un costo total $C$. Ahora estás explorando otra permutación parcial $\pi'$ y calculas el costo total parcial $C'$ de esta permutación parcial. Si $C' \geq C$, entonces puedes descartar esta rama de búsqueda (realizar una "poda"), ya que cualquier extensión de $\pi'$ resultará en un costo total mayor o igual a $C'$, y por lo tanto, nunca será mejor que la solución que ya tienes.

Ejemplo específico:
Imagina que ya has encontrado una solución $\pi = (1, 2, 3, 4)$ con un costo de $10$. Ahora estás explorando una solución parcial $\pi' = (2, 1, ...)$ y calculas el costo parcial de ir de 2 a 1 basado en tu matriz $D$, que resulta ser 11. Dado que este costo parcial ya es mayor que el costo total de tu mejor solución hasta ahora, puedes concluir de inmediato que continuar explorando esta rama no conducirá a una mejor solución. Por lo tanto, puedes podar esta rama y volver a una decisión anterior para intentar una ruta diferente.

Cómo demostrar que esta poda es correcta:
Para demostrar que una poda por optimalidad es correcta, necesitas argumentar que no estás descartando ninguna solución que pudiera ser mejor que tu mejor solución actual. En este caso, el argumento se basa en el hecho de que si el costo de una solución parcial ya excede el costo de la mejor solución completa encontrada hasta ahora, entonces, por definición, esa solución parcial (y cualquier extensión de ella) no puede resultar en una solución óptima

## Ejercicio 6 Optipago
#### Ej a. 
$$
Cc(c',q) = 
\begin{cases}
(0,0) & \text{si } c \leq 0 \\
(\infty, \infty) & \text{si } c > 0 \land B = \emptyset\\
\min\{Cc(B - b_{n}, c), Cc(B-b_{n}, c -b_{n}) + (0,1)\} & \text{ si } c > 0 \land B \neq \emptyset 
\end{cases}
$$


    def Cc(B, c, n): 
        if c <= 0: 
            return (0, 0) 
        if c > 0 and n == 0: 
            return (float('inf'), float('inf'))

        b_sin_ultimo, q_sin_ultimo = Cc(B, c, n-1)
        b_con_ultimo, q_con_ultimo = Cc(B, c - B[n-1],n-1)

        b_con_ultimo += B[n-1]  # Ajustamos el valor de pagar con el último billete
        q_con_ultimo += 1  # Ajustamos la cantidad de billetes al sumar el actual

        # Decidir cuál de los dos caminos tomar basándonos en el exceso y en la cantidad de billetes
        if b_sin_ultimo < b_con_ultimo or (b_sin_ultimo == b_con_ultimo and q_sin_ultimo <= q_con_ultimo):
            return (b_sin_ultimo, q_sin_ultimo)
        else:
            return (b_con_ultimo, q_con_ultimo)