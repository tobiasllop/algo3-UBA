# Práctica 2

## 2.1 Izquierda Dominante
Tenemos un arreglo llamemoslo a.

Sabemos que |a| = $2^n$

$$
IzqDom(a) = 
\begin{cases}
 True & \text{si } |a| = 2 \land a[0] < a[1]\\
False & \text{si } |a| = 2 \land a[0] > a[1]\\
\sum a_{izq} > \sum a_{der} \land 
        izqDom(a_{izq}) \land 
        izqDom(a_{der}) & \text{sino }
\end{cases}
$$

**Algoritmo**
        
        def izqDom(a):
            int mitad = len(a)/2
            izq = a[:mitad] #O(n/2)
            der = a[mitad:] #O(n/2)
            if len(a) == 2 and izq > der:
                return True
            if len(a) == 2 and izq < der:
                return False
            else:
                    return (sum(izquierda) > sum(derecha) #O(n) and 
                        esMasALaIzquierda(izquierda) and 
                        esMasALaIzquierda(derecha))

**Complejidad**: Si dividimos el arreglo de tamaño (n) en mitades hasta llegar a subarreglos de tamaño 2 (lo cual es el caso base), el número de niveles de división es $(log_2(n))$, y en cada nivel, realizas una cantidad de operaciones que es proporcional a (n) para comparar sumas. Por lo tanto, la complejidad del algoritmo es $(O(n \log n))$, que es estrictamente menor a $(O(n^2))$.

Estamos dividiendo un problema en a subproblemas de tamaño n/c. 
En este caso a=c=2.

Por resumen de cubawiki:
• a = c (“conquer lineal”, como en merge sort):
T(n) ∈ O(n log n)

## 2.2 IndiceEspejo
Se nos pide encontrar un elemento en un arreglo. Pienso en usar busqueda binaria ya que la complejidad es log n

        def indiceEspejo(a):
            low = 0
            high = len(a)-1
            while low <= high: #Busqueda binaria O(log n)
                mid = low + (high-low) / 2
                if a[mid] == mid:
                    return mid
                if a[mid] < mid:
                    low = mid + 1
                if a[mid] > mid:
                    high = mid - 1
            return 0 #No encontramos ninguno

**Complejidad** : Estamos dividiendo el problema en un solo subproblema y la combinacion de costo es constante:
 
 T(N) $\in$ O(log n).

O(log n) < O(n)

## 2.4 ComplexityQuest
1) T(n) = T(n-2) + 5

No podemos usar teorema maestro. Pero podemos ver que en cada llamado necesitamos el resultado de T(n-2) y sumarle 5. Como $O(n-2) \sim O(n)$ y  5 es O(1). Entonces suponemos que la complejidad será O(n).

3. $T(n) = T(n-1) + \sqrt{n}$

Creo que tampoco se puede sacar con teo maestro. Pero $O(n-1) \sim O(n)$ y en cada llamada se necesita $\sqrt{n}$. Por lo que la complejidad sería $O(n \cdot \sqrt{n}) = O(n^{3/2})$

6. $T(n) = T(n/2) + n$

Para usar el Teorema Maestro en el caso 6, primero vamos a entender qué nos dice este teorema. El Teorema Maestro nos proporciona una manera de determinar la complejidad temporal de algoritmos que pueden ser descritos mediante la ecuación de recurrencia $T(n) = aT(n/b) + f(n)$, donde:

* $a \geq 1$ es el número de subproblemas en la recursión.
* $n/b$ es el tamaño de cada subproblema. (Aquí se asume que todos los subproblemas tienen el mismo tamaño.)
* $f(n)$ es el costo de la parte no recursiva del algoritmo.
  
Dado el caso 6, donde $T(n) = T(n/2) + n$, podemos identificar que: - $a = 1$, porque hay un solo subproblema en cada paso recursivo. - $b = 2$, porque el tamaño del problema se reduce a la mitad en cada paso. - $f(n) = n$, porque el costo fuera de la recursión es lineal.

Para aplicar el Teorema Maestro, comparamos $f(n)$ con $n^{\log_b a} = n^{\log_2 1} = n^0 = 1$. Aquí, $f(n)$ crece más rápido que $n^{\log_b a}$, ya que $f(n) = n$ y $n > 1$ para $n > 1$.

De acuerdo con el Teorema Maestro, estamos en el caso 3, que se aplica cuando $f(n) = \Omega(n^{\log_b a + \epsilon})$ para algún $\epsilon > 0$. Aquí, $\epsilon$ puede ser 1, ya que $f(n) = n = n^{1} = n^{\log_b a + 1}$.

El teorema también exige que para algún $c < 1$ y suficientemente grande $n$, se cumpla que $af(n/b) \leq cf(n)$. Esto se cumple en nuestro caso ya que $f(n/2) = n/2$ y eligiendo $c = 1$, tenemos que $1(n/2) \leq 1(n)$.

Entonces, siguiendo el caso 3 del Teorema Maestro, la complejidad de $T(n) = T(n/2) + n$ es $O(f(n))$, es decir, $O(n)$.
